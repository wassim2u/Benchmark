ERROR: Exception occured during runtime!
Hyperparameters: model_name: t5-large, Batch_size: 32, dataset_size: all, max_gen_length: 128, beam_size: 4, max_input_seq_length: 15, tokenizer_padding_setting: pad_to_max_length, dataset_name= wmt14 
Full traceback message:
**********Traceback (most recent call last):
  File "benchmark_suite.py", line 879, in <module>
    evalEngine.call_batched(batch_size=batch_size,
  File "benchmark_suite.py", line 422, in call_batched
    outputs = self.model.generate(input_ids, do_sample=False, max_length=max_gen_length, num_beams=beam_size)
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/generation/utils.py", line 1611, in generate
    return self.beam_search(
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/generation/utils.py", line 2909, in beam_search
    outputs = self(
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 1720, in forward
    decoder_outputs = self.decoder(
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "benchmark_suite.py", line 91, in timer_forward
    result = orig_forward(cls, *args, **kwargs)
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 1090, in forward
    layer_outputs = layer_module(
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 693, in forward
    self_attention_outputs = self.layer[0](
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 600, in forward
    attention_output = self.SelfAttention(
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 525, in forward
    value_states = project(
  File "/home/wassim/miniconda3/envs/archer-env2/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py", line 506, in project
    hidden_states = torch.cat([past_key_value, hidden_states], dim=2)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 23.69 GiB total capacity; 9.95 GiB already allocated; 7.12 MiB free; 10.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
OrderedDict([('active.all.allocated', 126696687), ('active.all.current', 1437), ('active.all.freed', 126695250), ('active.all.peak', 1534), ('active.large_pool.allocated', 15895054), ('active.large_pool.current', 821), ('active.large_pool.freed', 15894233), ('active.large_pool.peak', 966), ('active.small_pool.allocated', 110801633), ('active.small_pool.current', 616), ('active.small_pool.freed', 110801017), ('active.small_pool.peak', 948), ('active_bytes.all.allocated', 304510353665536), ('active_bytes.all.current', 10681116672), ('active_bytes.all.freed', 304499672548864), ('active_bytes.all.peak', 20629485056), ('active_bytes.large_pool.allocated', 272571863271424), ('active_bytes.large_pool.current', 10675494912), ('active_bytes.large_pool.freed', 272561187776512), ('active_bytes.large_pool.peak', 20626808832), ('active_bytes.small_pool.allocated', 31938490394112), ('active_bytes.small_pool.current', 5621760), ('active_bytes.small_pool.freed', 31938484772352), ('active_bytes.small_pool.peak', 140680704), ('allocated_bytes.all.allocated', 304510353665536), ('allocated_bytes.all.current', 10681116672), ('allocated_bytes.all.freed', 304499672548864), ('allocated_bytes.all.peak', 20629485056), ('allocated_bytes.large_pool.allocated', 272571863271424), ('allocated_bytes.large_pool.current', 10675494912), ('allocated_bytes.large_pool.freed', 272561187776512), ('allocated_bytes.large_pool.peak', 20626808832), ('allocated_bytes.small_pool.allocated', 31938490394112), ('allocated_bytes.small_pool.current', 5621760), ('allocated_bytes.small_pool.freed', 31938484772352), ('allocated_bytes.small_pool.peak', 140680704), ('allocation.all.allocated', 126696687), ('allocation.all.current', 1437), ('allocation.all.freed', 126695250), ('allocation.all.peak', 1534), ('allocation.large_pool.allocated', 15895054), ('allocation.large_pool.current', 821), ('allocation.large_pool.freed', 15894233), ('allocation.large_pool.peak', 966), ('allocation.small_pool.allocated', 110801633), ('allocation.small_pool.current', 616), ('allocation.small_pool.freed', 110801017), ('allocation.small_pool.peak', 948), ('inactive_split.all.allocated', 64795717), ('inactive_split.all.current', 127), ('inactive_split.all.freed', 64795590), ('inactive_split.all.peak', 267), ('inactive_split.large_pool.allocated', 7324947), ('inactive_split.large_pool.current', 116), ('inactive_split.large_pool.freed', 7324831), ('inactive_split.large_pool.peak', 251), ('inactive_split.small_pool.allocated', 57470770), ('inactive_split.small_pool.current', 11), ('inactive_split.small_pool.freed', 57470759), ('inactive_split.small_pool.peak', 100), ('inactive_split_bytes.all.allocated', 159647834725888), ('inactive_split_bytes.all.current', 255531008), ('inactive_split_bytes.all.freed', 159647579194880), ('inactive_split_bytes.all.peak', 3293427200), ('inactive_split_bytes.large_pool.allocated', 123885602027008), ('inactive_split_bytes.large_pool.current', 252764160), ('inactive_split_bytes.large_pool.freed', 123885349262848), ('inactive_split_bytes.large_pool.peak', 3291668480), ('inactive_split_bytes.small_pool.allocated', 35762232698880), ('inactive_split_bytes.small_pool.current', 2766848), ('inactive_split_bytes.small_pool.freed', 35762229932032), ('inactive_split_bytes.small_pool.peak', 69491200), ('max_split_size', -1), ('num_alloc_retries', 1041), ('num_ooms', 1), ('oversize_allocations.allocated', 0), ('oversize_allocations.current', 0), ('oversize_allocations.freed', 0), ('oversize_allocations.peak', 0), ('oversize_segments.allocated', 0), ('oversize_segments.current', 0), ('oversize_segments.freed', 0), ('oversize_segments.peak', 0), ('requested_bytes.all.allocated', 301921971576087), ('requested_bytes.all.current', 10543568456), ('requested_bytes.all.freed', 301911428007631), ('requested_bytes.all.peak', 20627926144), ('requested_bytes.large_pool.allocated', 269993612265696), ('requested_bytes.large_pool.current', 10538000384), ('requested_bytes.large_pool.freed', 269983074265312), ('requested_bytes.large_pool.peak', 20625301504), ('requested_bytes.small_pool.allocated', 31928359310391), ('requested_bytes.small_pool.current', 5568072), ('requested_bytes.small_pool.freed', 31928353742319), ('requested_bytes.small_pool.peak', 140645489), ('reserved_bytes.all.allocated', 21050555367424), ('reserved_bytes.all.current', 10936647680), ('reserved_bytes.all.freed', 21039618719744), ('reserved_bytes.all.peak', 24310185984), ('reserved_bytes.large_pool.allocated', 20863007064064), ('reserved_bytes.large_pool.current', 10928259072), ('reserved_bytes.large_pool.freed', 20852078804992), ('reserved_bytes.large_pool.peak', 24299700224), ('reserved_bytes.small_pool.allocated', 187548303360), ('reserved_bytes.small_pool.current', 8388608), ('reserved_bytes.small_pool.freed', 187539914752), ('reserved_bytes.small_pool.peak', 157286400), ('segment.all.allocated', 703629), ('segment.all.current', 475), ('segment.all.freed', 703154), ('segment.all.peak', 1167), ('segment.large_pool.allocated', 614199), ('segment.large_pool.current', 471), ('segment.large_pool.freed', 613728), ('segment.large_pool.peak', 1099), ('segment.small_pool.allocated', 89430), ('segment.small_pool.current', 4), ('segment.small_pool.freed', 89426), ('segment.small_pool.peak', 75)])
**********
End of traceback message
Attempting to reduce batch size and retrying...
